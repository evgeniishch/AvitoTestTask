{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pretrained model\n",
    "bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased-conversational')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bert tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('DeepPavlov/rubert-base-cased-conversational')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the layers of the model before fine-tuning it\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        #relu activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        #dense layer 1\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        \n",
    "        #dense layer 2 (Output)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        \n",
    "        #sigmoid activation\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    # define forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        # pass inputs to the model\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "        \n",
    "        x = self.fc1(cls_hs)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #apply softmax\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass pre-trained BERT to our architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# pass the model to gpu\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_regexp = r'([87](\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}))'\n",
    "phone_regexp_simple = r'[8\\+7]?\\d{10,10}'\n",
    "phone_regexp_text = r'восемь девятьсот|семь девятьсот|восемь девятсот|семь девятсот|плюс семь'\n",
    "social_regexp = r'вк |vkcomid\\d{1,8}|вконтакте|tg |telegram|телеграм|в телегу|телега|тг |discord|дискорд|vkcom|okru|whatsapp|вотсап|ватсап|вайбер|viber|whats app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_str(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[:!.,\\-]', ' ', doc, re.I|re.A)\n",
    "    doc = re.sub(r'ё', 'е', doc, re.T|re.A)\n",
    "    doc = re.sub(r'[^a-zA-ZА-я\\s\\d]', ' ', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "\n",
    "    #extract phone number if any\n",
    "    text_numbers = re.sub(r'[a-zA-ZА-я\\s]','', doc, re.I|re.A)    \n",
    "    contains_phone_number = re.search(phone_regexp, text_numbers)\n",
    "    \n",
    "    contains_phone_as_text = re.search(phone_regexp_text, doc)\n",
    "    phone_trigger = 'PHONE_TRIGGER' if contains_phone_number or contains_phone_as_text else ''    \n",
    "    \n",
    "    #extract social links if any\n",
    "    contains_social_links = re.search(social_regexp, doc)\n",
    "    social_link_trigger = 'SOCIAL_TRIGGER' if contains_social_links else ''\n",
    "    \n",
    "    doc = re.sub(r'[^А-яa-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = re.sub(r'[a-zA-z\\d]{1,3}', '', doc, re.I|re.A)\n",
    "    doc = re.sub(r' \\w ', ' ', doc, re.A|re.I)\n",
    "    \n",
    "    #tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    \n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens) + ' ' + phone_trigger + ' ' + social_link_trigger\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data \n",
    "test_df = pd.read_csv('val.csv')\n",
    "\n",
    "test_df['text_data'] = test_df['title'] + ' ' + test_df['description']\n",
    "test_df = test_df.drop(labels=['title', 'description'], axis=1)\n",
    "\n",
    "test_df['text_data'] = test_df['text_data'].apply(normalize_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the test set\n",
    "tokens_test = tokenizer.batch_encode_plus(test_df['text_data'].tolist(),\n",
    "                                         max_length = 100,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_df['is_bad'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "\n",
    "#sampler for sampling the data during validation\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "\n",
    "#dataloader for validation set\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                            sampler=test_sampler,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights_v1.2.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    model.eval()\n",
    "    \n",
    "    total_preds = []\n",
    "    \n",
    "    # predict\n",
    "    for batch in test_dataloader:\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            \n",
    "            total_preds.append(preds)\n",
    "    \n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "       \n",
    "    return total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16237,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.T[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541475033497887"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_df['is_bad'], predictions.T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16237,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7997166964340703"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df['is_bad'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check within categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16237, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = test_df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_wrt_categories():\n",
    "    \n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    for category in categories:\n",
    "        current_category_entries = test_df[test_df['category'] == category]\n",
    "        cur_data = current_category_entries['text_data']\n",
    "        cur_labels = current_category_entries['is_bad']\n",
    "        \n",
    "        cur_tokens = tokenizer.batch_encode_plus(cur_data.tolist(),\n",
    "                                         max_length = 100,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         truncation=True)\n",
    "        \n",
    "        seq = torch.tensor(cur_tokens['input_ids'])\n",
    "        mask = torch.tensor(cur_tokens['attention_mask'])\n",
    "        cur_y = torch.tensor(cur_labels.tolist())\n",
    "        \n",
    "        batch_size = 32\n",
    "        \n",
    "        #wrap tensors\n",
    "        data = TensorDataset(seq, mask, cur_y)\n",
    "\n",
    "        #sampler for sampling the data during validation\n",
    "        sampler = SequentialSampler(data)\n",
    "\n",
    "        #dataloader for validation set\n",
    "        dataloader = DataLoader(data,\n",
    "                                sampler=sampler,\n",
    "                                batch_size=batch_size)\n",
    "        \n",
    "        model.eval()\n",
    "    \n",
    "        cur_preds = []\n",
    "\n",
    "        # predict\n",
    "        for batch in dataloader:\n",
    "            batch = [t.to(device) for t in batch]\n",
    "\n",
    "            sent_id, mask, labels = batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds = model(sent_id, mask)\n",
    "\n",
    "                preds = preds.detach().cpu().numpy()\n",
    "\n",
    "                cur_preds.append(preds)\n",
    "\n",
    "        cur_preds = np.concatenate(cur_preds, axis=0)\n",
    "        \n",
    "        cur_roc_auc = roc_auc_score(cur_labels, cur_preds.T[1])\n",
    "        \n",
    "        cur_preds_binary = np.argmax(cur_preds, axis=1)\n",
    "        \n",
    "        cur_accuracy = accuracy_score(cur_labels, cur_preds_binary)\n",
    "        \n",
    "        roc_auc_scores.append(cur_roc_auc)\n",
    "        print(\"ROC-AUC for \" + str(category) + \": \" + str(cur_roc_auc))\n",
    "        print(\"Accuracy for \" + str(category) + \": \" + str(cur_accuracy) + '\\n')\n",
    "    \n",
    "    mean_roc_auc = np.mean(roc_auc_scores)\n",
    "    print(\"Mean ROC-AUC: \" + str(mean_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC for Транспорт: 0.9421223439226712\n",
      "Accuracy for Транспорт: 0.9092232126614517\n",
      "\n",
      "ROC-AUC for Для бизнеса: 0.6999836547891468\n",
      "Accuracy for Для бизнеса: 0.8546712802768166\n",
      "\n",
      "ROC-AUC for Для дома и дачи: 0.8022317585418708\n",
      "Accuracy for Для дома и дачи: 0.8169968717413972\n",
      "\n",
      "ROC-AUC for Личные вещи: 0.7048453671133161\n",
      "Accuracy for Личные вещи: 0.7767705382436261\n",
      "\n",
      "ROC-AUC for Услуги: 0.7393583383064193\n",
      "Accuracy for Услуги: 0.6711309523809523\n",
      "\n",
      "ROC-AUC for Бытовая электроника: 0.7393918854642314\n",
      "Accuracy for Бытовая электроника: 0.8712338593974175\n",
      "\n",
      "ROC-AUC for Недвижимость: 0.721879018535597\n",
      "Accuracy for Недвижимость: 0.6630620375640296\n",
      "\n",
      "ROC-AUC for Хобби и отдых: 0.7419159161961644\n",
      "Accuracy for Хобби и отдых: 0.739021329987453\n",
      "\n",
      "ROC-AUC for Работа: 0.6802852122195189\n",
      "Accuracy for Работа: 0.6011029411764706\n",
      "\n",
      "ROC-AUC for Животные: 0.8177777777777778\n",
      "Accuracy for Животные: 0.7095238095238096\n",
      "\n",
      "Mean ROC-AUC: 0.7589791272866713\n"
     ]
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "test_wrt_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
